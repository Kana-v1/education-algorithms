keys - the numbers to be sorted
satelite data - kets associated with other data

record - keys and satelite data together

Time to resolve divide-and-conquer issue: 

T(n) = D(n) + a * T(n/b) + C(n)
where 
D(n) - time to divide the source problem
Source problem yields a subproblems, and it takes T(n/b) time to resolve each of them
C(n) - time to assemble subsolutions

The height of the binary tree = lg(n)

asymptomatic efficiency - how the running time of an algorithm increases with the size of the input without bound

O-notation - upper bound on the asymptomic notation


Matrix multiplication - divide-and-conquer

Open addressing - the family of methods that allow resolve hash function collisions 

get ith element from the statistics order (so you have array of distinct numbers, and you need ith element from this array in sorted view) - randomized select - O(n) or augmented red-black tree - O(lgn)

index of the matrix that is stored in the single-direction array:
    - starting index = s
    - emenents in the row = n
    - elements in the column = m

row-major order: s + (n * (i - s)) + (j - s) 

M = 1 2 3   
    4 5 6   

M[1, 2] = 0 + (3 * (1 - 0)) + (2 - 0) = 5

column-major order: s + (m * (j - s)) + (i - s)

    1 4
M = 2 5
    3 6

M[1, 2] = 0 + (2 * (2 - 0)) + (1 - 0) = 5

Left-child, right-sibling binary tree - easy to code representation of the random-number-of-childs binary tree


For using dynamic programming, subproblems have to be independent. For example, if you need to find the shortest and the longest paths:
you can divide this problem (A->B) into 2 subproblems: the shortest path A -> C, C -> B. So the shortest A -> B == A -> C -> B
However, the longest path A -> B != A -> C -> B

The subproblems are independent == they don't share resources

LCS (longest common subsequence) - X = (A;B;C;B;D;A;B), Y = (B;D;C;A;B;A). LCS = (B; C; B; A)


Greedy algorithm - make a choice that looks best for at the moment

Select activities - greedy choice. Select the best mutual compatible activities for the limited time

You should use greedy algorithm if the problem has 2 properties: 
1) You can assemble a globally optimal solution by making locally optimal (greedy) choices
2) A problem  exhibits  optimal  substructure  if an optimal solution to the problem contains within it optimal solutions to subproblems

Huffman codes compresses data well


Graph strongly connected components - set of vertices (each of that is the part of parent graph) that are reachable from each other 

minimum-spanning-tree problem - find a way to connect all vertices in the connected graph. Kruskal's  algorithm  and  Prim's  algorithm solve this problem, both take E * lg V, where E - set of pins, V - set of possible interconnections between pins

